#!/usr/bin/env python
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
#                                   Jiao Lin
#                      California Institute of Technology
#                        (C) 2007  All Rights Reserved
#
# {LicenseText}
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#



# by default, let us disable this annoying channel.
# one can always enable it by 
#  --journal.error.pyre.inventory
import journal
journal.error('pyre.inventory').deactivate()


# constants

# number of simulation loops by default (ncount/buffer_size)
DEFAULT_NUMBER_SIM_LOOPS = 5
# minimum buffer size
MINIMUM_BUFFER_SIZE = 100
MAXIMUM_BUFFER_SIZE = int(1e7)


from MpiApplication import Application as base
from CompositeNeutronComponentMixin import CompositeNeutronComponentMixin
from AppInitMixin import AppInitMixin
from ParallelComponent import ParallelComponent

class Instrument( AppInitMixin, CompositeNeutronComponentMixin, base, ParallelComponent ):

    class Inventory( base.Inventory ):

        import pyre.inventory
        
        #properties
        ncount = pyre.inventory.float('ncount', default = 10000)
        ncount.meta['tip'] = 'number of total neutrons generated by source'
        
        outputdir = pyre.inventory.str('output-dir', default = 'out')
        outputdir.meta['tip'] = 'output directory'

        overwrite_datafiles = pyre.inventory.bool(
            'overwrite-datafiles',  default = False)
        overwrite_datafiles.meta['tip'] = 'overwrite data files?'
        
        buffer_size = pyre.inventory.int  ('buffer_size', default = 0)
        buffer_size.meta['tip']= 'size of neutron buffer. This is for optimizing the preformance of the simulation. When it is too large, it will occupy too much memory. When it is too small, the simulation will be slow. If you are not sure, please just leave it unset so that the default value will be used.'

        from List import List
        sequence = List( 'sequence', default = '' )
        sequence.meta['tip'] = 'sequence of neutron components in this instrument'

        multiple_scattering = pyre.inventory.bool('multiple-scattering', default=False)
        multiple_scattering.meta['tip'] = 'if true, enable multiple scattering'

        #facilities

        #geometer. this is a place holder. should derive from Geometer
        #to create a new Geometer for the specific instrument.
        from Geometer import Geometer
        geometer = pyre.inventory.facility(
            'geometer', default = Geometer() )
        geometer.meta['tip'] = 'geometer of instrument'

        # tracer
        from NoNeutronTracer import NoNeutronTracer
        from NeutronTracerFacility import NeutronTracerFacility
        tracer = NeutronTracerFacility('tracer', default=NoNeutronTracer())

        # this option overrides "dumpconfiguration" to provide an iinterface
        # easier to use
        dumppml = pyre.inventory.str('dump-pml', default='')
        dumppml.meta['tip'] = "filename of output configuration (pml) file. if empty, ignored. if the given value is 'yes' or 'on', a default filename will be used."

        # XXX: to be removed
        # for backward compatibility
        dump_instrument = pyre.inventory.bool('dump-instrument')

        # dump registry to pkl file
        # this is for advanced users. the saved registry can be compared
        # to another saved registry, for example.
        dumpregistry = pyre.inventory.bool('dump-registry', default=False)
        dumpregistry.meta['tip'] = 'if true, dump the pyre registry to a pkl file'

        # path of the directory with post processing scripts
        # the components that need post-processing should add scripts
        # to this directory
        post_processing_scripts_dir = pyre.inventory.str("post-processing-scripts-dir")
        pass # end of Inventory


    def __init__(self, name):
        base.__init__(self, name)
        self._warning = journal.warning( name )
        return


    def help(self):
        print '------------------------------------------------------------'
        print '* Instrument simulation application %r' % self.name
        print '------------------------------------------------------------'
        print '* Sequence of components:'
        print '  ', self._componentListStr()
        print '------------------------------------------------------------'
        print '* Command:'
        print self._cmdlineDemoStr()
        print '------------------------------------------------------------'
        return


    def main(self, *args, **kwds):
        if self.inventory.dumpregistry:
            self._dumpRegsitry()
            return
        
        import mcni
        instrument = self._createInstrument()
        
        geometer = self.geometer

        context = self._makeSimContext()
        
        n = int(self.ncount / self.buffer_size)
        assert n>0, 'ncount should be larger than buffer_size: ncount=%s, buffer_size=%s' % (self.ncount, self.buffer_size)
        
        from mcni import journal
        logger = journal.logger(
            'info', 'instrument', header='', footer='', format='-> %s')
        for i in range(n):
            logger("mpi node %s at loop %s" % (self.mpi.rank, i))
            neutrons = mcni.neutron_buffer( self.buffer_size )
            context.iteration_no = i
            mcni.simulate( instrument, geometer, neutrons, context=context)
            continue
        
        remain = int(self.ncount % self.buffer_size)
        if remain:
            logger("mpi node %s at last loop" % (self.mpi.rank,))
            neutrons = mcni.neutron_buffer(remain)
            context.iteration_no = n
            mcni.simulate( instrument, geometer, neutrons, context=context)
            
        print os.times()
        return


    def run_postprocessing(self):
        _run_ppsd(self.post_processing_scripts_dir)
        return


    def _makeSimContext(self):
        from mcni.SimulationContext import SimulationContext
        context = SimulationContext()
        context.multiple_scattering = self.inventory.multiple_scattering
        context.tracer = self.tracer
        context.mpiRank = self.mpi.rank
        context.mpiSize = self.mpi.size
        context.outputdir = self.outputdir
        context.overwrite_datafiles = self.overwrite_datafiles
        pps = self.inventory.post_processing_scripts_dir
        if not pps:
            pps = os.path.join(self.outputdir, 'post-processing-scripts')
        self.post_processing_scripts_dir = context.post_processing_scripts_dir = pps
        if context.mpiRank==0 and not os.path.exists(pps):
            os.makedirs(pps)
        return context

        
    def _dumpRegsitry(self):
        out = '%s-reg.pkl' % self.name
        if os.path.exists(out):
            raise RuntimeError, 'dump registry: path %s already exists' % out

        from pyre.applications.Application import retrieveConfiguration
        reg = self.createRegistry()
        retrieveConfiguration(self.inventory, reg)
        from RegistryToDict import Renderer
        renderer = Renderer()
        reg = renderer.render(reg)
        
        import pickle
        pickle.dump(reg, open(out, 'w'))
        return


    def _createInstrument(self):
        neutron_components = self.neutron_components
        for comp in neutron_components:
            if comp not in self.sequence:  
                self._warning.log(
                    'component %s was not included in component sequence %s' % (
                    comp, self.sequence )
                    )
                pass
            continue
        
        for name in self.sequence:
            if name not in neutron_components:
                raise RuntimeError , "Neutron component %s specified in sequence %s does not " \
                      "correspond to any known simulation components: %s" % (
                    name, self.sequence, neutron_components )
            continue

        import mcni
        components = [ neutron_components[ name ] for name in self.sequence ]
        instrument = mcni.instrument( components )
        return instrument
    
    
    def _defaults(self):
        base._defaults(self)
        self.inventory.geometer = _build_geometer( self )
        return
    
    
    def _setup_outputdir(self):
        self.mpi.barrier()
        outputdir = self.outputdir = self.inventory.outputdir
        if self.parallel and self.mpi.rank==0 and self.inventory.mode=='worker':
            if not self.overwrite_datafiles and os.path.exists( outputdir ):
                msg = "output directory %r exists. If you want to overwrite the output directory, please specify option --overwrite-datafiles." % outputdir
                raise RuntimeError, msg

            if not os.path.exists( outputdir ):
                os.makedirs( outputdir )
                pass

        return
    
    
    def _configure(self):

        # XXX: to be removed
        # XXX: for backward compatibility
        dump_instrument = self.inventory.dump_instrument
        if dump_instrument:
            import warnings
            warnings.warn('This option is not supported anymore. Please use --dump-pml')
        
        # handle dumppml
        # this overrides the option dumpconfiguration in order to
        # provide a simpler interface for users.
        dumppml = self.inventory.dumppml
        if dumppml:
            self.inventory.dumpconfiguration = True
            self._showHelpOnly = True

        base._configure(self)
        self.geometer = self.inventory.geometer
        self.overwrite_datafiles = self.inventory.overwrite_datafiles
        
        self.sequence = self.inventory.sequence
        if self.inventory.mode == 'worker':
            self.buffer_size = self._getBufferSize()
            self.ncount = self.inventory.ncount
            if self.parallel:
                # every node only need to run a portion of the total counts
                partitions = getPartitions(self.ncount, self.mpi.size)
                self.ncount = partitions[self.mpi.rank]

        # tracer
        tracer = self.inventory.tracer
        if tracer.name == 'no-neutron-tracer':
            tracer = None
        self.tracer = tracer
        
        return


    def _init_before_my_inventory(self):

        super(Instrument, self)._init_before_my_inventory()

        # output directory
        if not self._showHelpOnly and self.inventory.mode == 'worker': 
            self._setup_outputdir()

        #
        self._find_all_neutron_subcomponents()
        
        # if in server mode for parallel computing
        # we actually don't want the subcomponents to
        # initialize, because in the "server" mode 
        # the application just call launcher to 
        # let workers start working.
        # this logic probably should go into class MpiApplication.
        # Please read MpiApplication._init as well!
        # 
        self.mpi_server_mode = self.inventory.mode == 'server'
        # mpi_server_mode is true means that it is not a worker,
        # and no initialization is necessary for all neutron sub-components
        # we can just set _showHelpOnly for them.
        # We cannot just set the application _showHelpOnly since
        # we need this application to start the workers.
        # There should be a more systematic way of dealing with this
        # in pyre.
        if self.mpi_server_mode:
            for comp in self.neutron_components.itervalues():
                comp._showHelpOnly = True
        return

    
    def _init(self):
        super(Instrument, self)._init()
        # XXX
        # if I am in server mode for the mpi application,
        # I told my sub components to not to initialize 
        # (see _init_before_my_inventory). 
        # and that results in my _showHelpOnly flag set.
        # I need to revert that flag so that I can run
        # my workers.
        # That is really confusing. We actually need a separate
        # flat that just indicate whether the user is requesting
        # for help, or there are other reasons for which some
        # components should not be initialized.
        # need to modify pyre for that.
        if self.mpi_server_mode:
            self._showHelpOnly = False
        return


    def _getBufferSize(self):
        # user requested size
        usersize = self.inventory.buffer_size
        # 
        if not usersize:
            return self._computeBufferSize()

        maxsize = self._maximumBufferSize()
        if usersize > maxsize:
            return maxsize

        minsize = self._minimumSuggestedBufferSize()
        if usersize < minsize:
            import warnings
            warnings.warn("The buffer size %s is too small" % usersize)
            
        return usersize


    def _minimumSuggestedBufferSize(self):
        return self.inventory.ncount / 1000 / (self.mpi.size or 1)
    
    
    def _computeBufferSize(self):
        ncount = self.inventory.ncount
        mpisize = self.mpi.size or 1
        nsteps = DEFAULT_NUMBER_SIM_LOOPS
        candidate = int(ncount/nsteps/mpisize)
        # rare case where ncount is way too small
        if candidate < 1:
            candidate = int(ncount/mpisize)
            if candidate < 1:
                candidate = ncount
        return min(self._maximumBufferSize(), candidate)
    
    
    def _maximumBufferSize(self):
        # XXX need to tell if we are in the shared memory machine
        # XXX or not. for now, let us play safe
        nodes = self.mpi.size or 1
        return min(
            _computeMaximumBufferSize(nodes),
            MAXIMUM_BUFFER_SIZE,
            )
    
    
    def _saveConfiguration(self):
        # the default configuration filename
        default_filename = '%s.pml' % self.name
        
        # the given filename
        dumppml = self.inventory.dumppml
        if dumppml in ['yes', 'on', 'true']:
            outfile = default_filename
        else:
            outfile = dumppml

        # make sure the output path does not exist
        if os.path.exists(outfile):
            # save the old configuration 
            timeformat = '%m-%d-%Y--%H-%M-%S'
            import time, shutil
            timestr = time.strftime(timeformat)
            newfilename = '%s.saved-%s' % (outfile, timestr)
            shutil.copyfile(outfile, newfilename)

        # get registry
        registry = self.createRegistry()
        exclude_props = [
            'weaver',
            'typos',
            'dumpconfiguration', 'dumpconfiguration-output',
            'help-properties', 'help', 'help-persistence', 'help-components',
            'dump-pml',
            'buffer_size',
            'mode',
            ]
        from pyre.applications.Application import retrieveConfiguration
        registry = retrieveConfiguration( 
            self.inventory, registry, excludes=exclude_props)
        
        # the output stream
        stream = open(outfile, 'w')

        # weave
        self.weaver.weave( registry, stream )

        # footer
        stream.write('<!-- \n automatically created by the following command:\n')
        cmd = _getCmdStr()
        stream.write(' $ %s\n' % cmd)
        stream.write('-->\n\n')

        # give a warning when use non-default config filename
        base = os.path.basename(outfile)
        if base != default_filename:
            print '*'*70
            print "Warning: you will need to rename file %s to %s, otherwise this file won't be used by the simulation application %s" % (
                outfile, default_filename, os.path.basename(sys.argv[0]))
            print '*'*70
        return
    
    
    def _componentListStr(self):
        comps = self.neutron_components
        l = []
        for name in self.inventory.sequence:
            comp = comps[name]
            if hasattr(comp, 'uri'): uri = comp.uri
            else: uri = comp.name
            l.append( (name, uri) )
            continue
        return ' --> '.join(['[%s(%s)]' % (n, u) for n,u in l])
        

    def _cmdlineDemoStr(self):
        s = ' $ %s ' % self.name
        opts = []
        skipappprops=['name', 'typos', 'journal', 'geometer', 'sequence', 'weaver']+\
            self.inventory.sequence

        from _invutils import getComponentPropertyNameTipPairs
        appopts = getComponentPropertyNameTipPairs(self, skipappprops)
        opts += [(n, '<%s>'%tip) for n, tip in appopts]
        for comp in self.inventory.sequence:
            opts.append( ('geometer.%s' % comp, '<position>,<orientation>') )
            continue
        for name in self.inventory.sequence:
            opts.append( (name, '<component type>') )
            continue
        components = self.neutron_components
        for name in self.inventory.sequence:
            comp = components[name]
            pairs = getComponentPropertyNameTipPairs(comp)
            pairs = [ ('%s.%s' % (name, n), '<%s>' % (tip,)) for n, tip in pairs]
            opts += pairs
            continue
        l = [s] + ['  --%s=%s' % (k,v) for k, v in opts]
        return ' \\\n'.join(l) 


    # overwrite processCommandline so that we know
    # user is requesting for help and avoid unecessary
    # initialization and finalization of components
    def processCommandline(self, registry):
        ret = super(Instrument, self).processCommandline(registry)
        help = ret[0]
        if help: self._showHelpOnly = True
        return ret
    

    pass # end of Instrument




def _computeMaximumBufferSize(nodes):
    """number of nodes.

    This actually depends on the system mcvine is running on.

    If we are running on one machine that has shared memory, we need
    to set here nodes to the number of mpi instances.

    If we are running on a cluster of nodes without shared memory,
    we should not need to divide the maximum buffer size by nodes.
    """
    import psutil
    vm = psutil.virtual_memory()
    memsize = min(vm.total/2, vm.available*0.85)
    memsize = int(memsize)
    from mcni.neutron_storage.idfneutron import ndblsperneutron

    bytesperdble = 8
    minsize = MINIMUM_BUFFER_SIZE

    n = int(memsize/nodes/ndblsperneutron/bytesperdble/minsize) \
        *MINIMUM_BUFFER_SIZE

    if n<minsize:
        raise RuntimeError, "Not enough memory"

    return n


def _run_ppsd(path):
    "run postprocessing scripts in the given path"
    import glob
    scripts = glob.glob(os.path.join(path, '*.py'))
    for script in scripts:
        cmd = '%s %s' % (sys.executable, script)
        _exec(cmd)
        continue
    return

def _exec(cmd):
    if os.system(cmd):
        raise RuntimeError("%s failed" % cmd)
    return

def _getCmdStr():
    import sys, os
    argv = list(sys.argv)
    argv[0] = os.path.basename(argv[0])
    for i,t in enumerate(argv):
        if t.startswith('--'): argv[i] = '-'+t[2:]
        continue
    return ' '.join(argv)


def _build_geometer( instrument ):
    from _geometer_utils import buildGeometerFromInventory
    Inventory = instrument.Inventory
    g = buildGeometerFromInventory(Inventory)
    g.instrument = instrument
    return g
    

def getPartitions(N, n):
    return list(getPartitionIterator(N,n))

def getPartitionIterator( N, n ):
    '''create an iterator of n partitions where the sum of all partions is N
    All partitions should be about the same size.
    '''
    from math import ceil
    residual = N
    nbins = n
    while residual:
        if nbins > 1:
            size = int( ceil(residual*1./nbins) )
        else:
            size = residual
        yield size
        residual -= size
        nbins -= 1
    return 


import os, sys, journal


# version
__id__ = "$Id$"

# End of file 
